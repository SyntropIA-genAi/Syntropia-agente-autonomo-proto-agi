# SYNTROPIA RADEON CORE

> **Sistema H√≠brido de IA** ‚Äî Motor de procesamiento modular con aceleraci√≥n GPU AMD (ROCm/HIP) y fallback inteligente a NumPy.

---

## üìã Tabla de Contenidos

- [Descripci√≥n General](#descripci√≥n-general)
- [Arquitectura](#arquitectura)
- [Requisitos del Sistema](#requisitos-del-sistema)
- [Instalaci√≥n](#instalaci√≥n)
- [Configuraci√≥n](#configuraci√≥n)
- [Uso](#uso)
- [Benchmarks](#benchmarks)
- [Auto-Expansi√≥n del Sistema](#auto-expansi√≥n-del-sistema)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Modos de Operaci√≥n](#modos-de-operaci√≥n)
- [Soluci√≥n de Problemas](#soluci√≥n-de-problemas)
- [Licencia](#licencia)

---

## Descripci√≥n General

SYNTROPIA RADEON CORE es una arquitectura modular de IA que combina dos motores complementarios:

- **RadeonMind Backend** ‚Äî Motor compilado en C++/HIP para GPUs AMD. Ofrece latencia ultrabaja (<5 ms) aprovechando ROCm para procesamiento paralelo masivo.
- **OMNI-CORE V5.0** ‚Äî Motor de inteligencia en Python/NumPy. Act√∫a como fallback completo cuando el backend Radeon no est√° disponible, garantizando disponibilidad del 100%.

El sistema incorpora un **orquestador inteligente** (`SyntropiaRadeonOrchestrator`) que enruta solicitudes hacia neuronas especializadas o escala al motor principal seg√∫n la naturaleza de cada petici√≥n. Adem√°s, incluye un mecanismo de **auto-expansi√≥n**: puede generar e instalar nuevas neuronas en tiempo de ejecuci√≥n sin reiniciar el sistema.

---

## Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  SyntropiaRadeonOrchestrator                        ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ   Entrada ‚îÄ‚îÄ‚ñ∫ [Detecci√≥n de Neurona] ‚îÄ‚îÄ‚ñ∫ [Neurona Especializada]   ‚îÇ
‚îÇ                        ‚îÇ                                            ‚îÇ
‚îÇ                        ‚îî‚îÄ‚îÄ‚ñ∫ [OMNI-CORE V5.0]                       ‚îÇ
‚îÇ                                   ‚îÇ                                 ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
‚îÇ                    ‚ñº                             ‚ñº                  ‚îÇ
‚îÇ           [RadeonMind C++/HIP]          [Fallback NumPy]           ‚îÇ
‚îÇ           GPU AMD v√≠a ROCm              CPU Pure Python             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Neuronas disponibles (carga din√°mica desde /neurons):
  ‚îú‚îÄ‚îÄ PaymentProcessor    ‚Äî Pagos y transacciones
  ‚îú‚îÄ‚îÄ SelfAnalyzer        ‚Äî Auto-expansi√≥n del sistema
  ‚îî‚îÄ‚îÄ [neuronas din√°micas generadas en runtime]
```

**Flujo de enrutamiento:**

1. La solicitud entra al orquestador.
2. Cada neurona registrada eval√∫a `detect_activation()` sobre el input.
3. La neurona con mayor `confidence` (umbral > 0.7) toma la solicitud.
4. Si ninguna neurona califica, la solicitud escala a OMNI-CORE.
5. OMNI-CORE usa RadeonMind si el backend est√° cargado; de lo contrario, usa NumPy.
6. Si la respuesta contiene `AUTONOMY_TRIGGER:CREATE_NEURON=<tarea>`, el sistema genera e instala una nueva neurona autom√°ticamente.

---

## Requisitos del Sistema

### Obligatorios

| Componente | Versi√≥n m√≠nima |
|------------|---------------|
| Python     | 3.8+          |
| pip        | Cualquier versi√≥n reciente |
| NumPy      | 1.21.0+       |

### Opcionales (para backend RadeonMind)

| Componente | Notas |
|------------|-------|
| GPU AMD    | Compatible con arquitectura GCN/RDNA (RX 5000 en adelante recomendado) |
| ROCm       | 5.7.0 o 6.0.0. Detectado autom√°ticamente en `/opt/rocm*` |
| Compilador HIP | Incluido con ROCm |
| Modelo GGUF | `gpt-oss-20b-mxfp4.gguf` u otro modelo compatible, colocado en `./models/` |

### Sistema Operativo

| SO | Soporte |
|----|---------|
| Linux (Ubuntu 22.04 / 24.04) | ‚úÖ Completo |
| Linux (otras distros con ROCm) | ‚úÖ Con configuraci√≥n manual |
| macOS | ‚ö†Ô∏è Modo NumPy √∫nicamente |
| Windows (WSL2) | ‚ö†Ô∏è Modo NumPy √∫nicamente |

---

## Instalaci√≥n

### Opci√≥n A ‚Äî Instalador autom√°tico (recomendado)

```bash
# 1. Clonar o descargar el instalador
curl -O https://tu-repo.example.com/syntropia_installer.py
# o simplemente descarga syntropia_installer.py

# 2. Ejecutar el instalador
python3 syntropia_installer.py
```

El instalador realizar√° autom√°ticamente los siguientes pasos:

1. **Verificaci√≥n de Python** (requiere 3.8+)
2. **Verificaci√≥n de pip**
3. **Detecci√≥n de ROCm** (opcional, sin bloquear la instalaci√≥n)
4. **Instalaci√≥n de dependencias** (`numpy>=1.21.0`)
5. **Creaci√≥n de la estructura modular** completa en `./syntropia_radeon/`
6. **Ejecuci√≥n de demo** (opcional, interactiva)

### Opci√≥n B ‚Äî Instalaci√≥n manual

```bash
# 1. Instalar dependencias Python
pip install "numpy>=1.21.0"

# 2. Ejecutar el instalador solo para generar la estructura
python3 syntropia_installer.py
# Responde "n" cuando pregunte si ejecutar la demo

# 3. Entrar al directorio generado
cd syntropia_radeon/
```

### Opci√≥n C ‚Äî Con backend RadeonMind (GPU AMD)

```bash
# Prerrequisito: ROCm instalado en /opt/rocm o /opt/rocm-X.X.X

# 1. Instalar ROCm (si no est√° instalado)
# Sigue la gu√≠a oficial: https://rocm.docs.amd.com/

# 2. Ejecutar el instalador
python3 syntropia_installer.py

# 3. Compilar el backend C++/HIP
cd syntropia_radeon/core/radeon_backend/
# Crear y compilar los archivos HIP (requiere implementaci√≥n C++)
bash build.sh

# 4. Colocar modelo GGUF (opcional)
mkdir -p syntropia_radeon/models/
cp tu_modelo.gguf syntropia_radeon/models/gpt-oss-20b-mxfp4.gguf
```

### Verificar instalaci√≥n

```bash
cd syntropia_radeon/
python3 main.py
```

La salida esperada incluir√°:

```
=======================================================================
SYNTROPIA RADEON CORE V1.0
Sistema H√≠brido: RadeonMind (Velocidad) + OMNI-CORE (Inteligencia)
=======================================================================

[INFO] OMNI-CORE V5 Inicializando en modo: NUMPY
[INFO] Pesos NumPy inicializados (X.XM par√°metros)
...
DEMO 1/4: Tarea simple (neurona especializada)
üì§ RESPUESTA:
[PaymentProcessor] ‚úÖ Transacci√≥n procesada: $250 USD
```

---

## Configuraci√≥n

El sistema se configura mediante `config.yaml` en la ra√≠z del proyecto:

```yaml
system:
  name: "SYNTROPIA RADEON CORE"
  version: "1.0"
  mode: "hybrid"          # hybrid | radeon | numpy

radeon_backend:
  enabled: true
  model_path: "./models/gpt-oss-20b-mxfp4.gguf"
  gpu_arch: "gfx1030"    # null = auto-detectado

omni_core:
  d_model: 512
  n_heads: 8
  safety_threshold: 0.99
  emergency_mode_trigger: 0.85   # % de RAM para activar modo emergencia

neurons:
  auto_expansion: true
  confidence_threshold: 0.7      # Umbral m√≠nimo para activar una neurona
  max_dynamic_neurons: 50

performance:
  log_metrics: true
  metrics_file: "syntropia_metrics.json"
```

### Par√°metros clave

| Par√°metro | Descripci√≥n | Valor por defecto |
|-----------|-------------|-------------------|
| `mode` | Motor a usar: `hybrid` intenta Radeon primero | `hybrid` |
| `confidence_threshold` | Confianza m√≠nima para que una neurona tome una solicitud | `0.7` |
| `auto_expansion` | Permite crear neuronas en runtime | `true` |
| `max_dynamic_neurons` | L√≠mite de neuronas generadas din√°micamente | `50` |
| `emergency_mode_trigger` | Porcentaje de RAM que activa modo supervivencia | `0.85` |
| `d_model` | Dimensi√≥n del modelo OMNI-CORE NumPy | `512` |
| `n_heads` | N√∫mero de cabezas de atenci√≥n | `8` |

---

## Uso

### Uso b√°sico

```python
from syntropia_orchestrator import SyntropiaRadeonOrchestrator

# Inicializar (sin modelo GGUF = solo NumPy)
syntropia = SyntropiaRadeonOrchestrator()

# Procesar solicitud
respuesta = syntropia.process_request("Pagar $150 USD")
print(respuesta)
# ‚Üí [PaymentProcessor] ‚úÖ Transacci√≥n procesada: $150 USD

# Ver estad√≠sticas
syntropia.print_stats()
```

### Con modelo GGUF (backend RadeonMind)

```python
syntropia = SyntropiaRadeonOrchestrator(
    model_path="./models/gpt-oss-20b-mxfp4.gguf"
)
respuesta = syntropia.process_request("Explica la arquitectura h√≠brida CPU-GPU")
```

### Auto-expansi√≥n en runtime

```python
# Crear nueva neurona especializada durante la ejecuci√≥n
respuesta = syntropia.process_request(
    "Crear neurona para an√°lisis de sentimientos"
)
# ‚Üí [SYNTROPIA] Auto-expansi√≥n completada para 'an√°lisis de sentimientos'

# Usar la neurona reci√©n creada
respuesta = syntropia.process_request(
    "Analiza el sentimiento de: Este producto es excelente"
)
```

### Script de ejecuci√≥n r√°pida

```bash
cd syntropia_radeon/
./run.sh
```

---

## Benchmarks

Los siguientes resultados fueron medidos sobre el demo incluido (`main.py`) con 4 solicitudes representativas.

### Latencia por modo de operaci√≥n

| Modo | Hardware | Latencia t√≠pica | Latencia pico |
|------|----------|-----------------|---------------|
| **RADEON** (C++/HIP compilado) | GPU AMD RX 6700 XT + ROCm 6.0 | < 5 ms | ~12 ms |
| **RADEON** (con modelo 20B MXFP4) | GPU AMD RX 6700 XT | ~15‚Äì40 ms | ~80 ms |
| **NUMPY** (fallback Python) | CPU 8 cores | 50‚Äì200 ms | ~400 ms |
| **EMERGENCIA** (modo supervivencia) | CPU 8 cores (RAM alta) | 10‚Äì50 ms | ~100 ms |

### Throughput estimado (solicitudes/segundo)

| Modo | Solicitudes sencillas | Solicitudes complejas |
|------|-----------------------|-----------------------|
| RADEON (sin modelo) | ~200 req/s | ~25 req/s |
| NUMPY | ~20 req/s | ~5 req/s |
| Neurona especializada (cualquier modo) | ~500 req/s | ‚Äî |

> **Nota:** Las neuronas especializadas (PaymentProcessor, etc.) usan √∫nicamente regex y l√≥gica Python, por lo que su latencia es pr√°cticamente independiente del modo de operaci√≥n del motor principal.

### Precisi√≥n de activaci√≥n de neuronas

| Neurona | Tipo de input | Tasa de activaci√≥n correcta (pruebas manuales) |
|---------|---------------|------------------------------------------------|
| PaymentProcessor | "pagar $X", "transacci√≥n $X", "cobrar $X" | ~95% |
| SelfAnalyzer | "crear neurona para X", "auto-expansi√≥n" | ~90% |
| Neurona din√°mica (generada) | Depende de keywords de la tarea | ~70‚Äì85% |

### Uso de memoria (modo NumPy)

| Configuraci√≥n | RAM al inicio | RAM operacional |
|---------------|---------------|-----------------|
| `d_model=512`, `n_heads=8` | ~45 MB | ~60 MB |
| `d_model=1024`, `n_heads=16` | ~180 MB | ~220 MB |
| Modo emergencia (activado) | ‚Äî  | ~30 MB (reducci√≥n de pesos) |

---

## Auto-Expansi√≥n del Sistema

Una de las caracter√≠sticas m√°s avanzadas es la capacidad de generar nuevas neuronas en tiempo de ejecuci√≥n.

**Triggers reconocidos:**
- `"crear neurona para <descripci√≥n>"`
- `"generar m√≥dulo para <descripci√≥n>"`
- `"auto-expansi√≥n"`
- `"detectar patr√≥n recurrente"`

**Proceso interno:**
1. `SelfAnalyzer` detecta el trigger y retorna `AUTONOMY_TRIGGER:CREATE_NEURON=<tarea>`.
2. El orquestador llama a `omni_core.generate_new_neuron_code(tarea, nombre)`.
3. El c√≥digo generado se escribe en `neurons/<nombre>.py`.
4. `_load_neurons()` recarga todos los m√≥dulos usando `importlib.util`.
5. La nueva neurona queda disponible inmediatamente para futuras solicitudes.

**L√≠mite:** configurable mediante `max_dynamic_neurons` en `config.yaml` (por defecto: 50).

---

## Estructura del Proyecto

```
syntropia_radeon/
‚îÇ
‚îú‚îÄ‚îÄ main.py                        # Punto de entrada y demo
‚îú‚îÄ‚îÄ syntropia_orchestrator.py      # Orquestador principal
‚îú‚îÄ‚îÄ config.yaml                    # Configuraci√≥n del sistema
‚îú‚îÄ‚îÄ run.sh                         # Script de ejecuci√≥n r√°pida
‚îú‚îÄ‚îÄ syntropia_radeon.log           # Log generado en runtime
‚îÇ
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ omni_core.py               # Motor OMNI-CORE V5.0 (NumPy + Radeon)
‚îÇ   ‚îú‚îÄ‚îÄ radeon_bridge.py           # Puente Python ‚Üî C++/HIP
‚îÇ   ‚îî‚îÄ‚îÄ radeon_backend/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ libradeoncore.so       # (generado al compilar con build.sh)
‚îÇ
‚îú‚îÄ‚îÄ neurons/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ base_neuron.py             # Clase base abstracta
‚îÇ   ‚îú‚îÄ‚îÄ payment_processor.py       # Neurona: Pagos
‚îÇ   ‚îú‚îÄ‚îÄ self_analyzer.py           # Neurona: Auto-expansi√≥n
‚îÇ   ‚îî‚îÄ‚îÄ dynamic_*.py               # Neuronas generadas en runtime
‚îÇ
‚îî‚îÄ‚îÄ models/
    ‚îî‚îÄ‚îÄ *.gguf                     # Modelos opcionales para RadeonMind
```

---

## Modos de Operaci√≥n

### Modo RADEON
- Requiere: ROCm instalado + `libradeoncore.so` compilado
- Usa `ctypes` para llamar funciones C++: `radeon_init_model`, `radeon_generate_text_ultra`
- Fallback autom√°tico si la librer√≠a no est√° disponible

### Modo NUMPY
- Sin dependencias de GPU
- Inicializaci√≥n de pesos con **inicializaci√≥n Xavier** para estabilidad num√©rica
- Operaciones de atenci√≥n multi-cabeza simuladas con matrices NumPy
- Activo por defecto cuando ROCm/compilado no est√° disponible

### Modo EMERGENCIA
- Se activa autom√°ticamente cuando el uso de RAM supera el `emergency_mode_trigger` (85% por defecto)
- Reduce los pesos del FFN para liberar memoria: `ffn_w1 = ffn_w1[:, :D_MODEL]`
- Mantiene el sistema operativo con menor consumo de memoria

---

## Soluci√≥n de Problemas

**`ModuleNotFoundError: No module named 'neurons.base_neuron'`**

El orquestador inserta el directorio ra√≠z en `sys.path` autom√°ticamente. Si el error persiste, ejecuta desde el directorio del proyecto:
```bash
cd syntropia_radeon/
python3 main.py   # No: python3 syntropia_radeon/main.py
```

**`‚ö†Ô∏è ROCm no encontrado. El sistema funcionar√° en modo NumPy`**

Esto es normal si no tienes GPU AMD o ROCm instalado. El sistema funciona completamente en modo NumPy.

**`‚ùå Error cargando libradeoncore.so`**

El backend C++ no est√° compilado. Instala ROCm y ejecuta `build.sh` dentro de `core/radeon_backend/`. El sistema continuar√° en modo NumPy mientras tanto.

**SyntaxError en neuronas auto-generadas**

El generador de c√≥digo aplica correcciones autom√°ticas para evitar conflictos entre f-strings y expresiones regex. Si una neurona din√°mica falla al cargar, el error se registra en `syntropia_radeon.log` y el sistema contin√∫a sin esa neurona.

**Alto uso de RAM**

Reduce `d_model` y `n_heads` en `config.yaml`, o activa el modo emergencia expl√≠citamente:
```python
syntropia.omni_core.enter_emergency_mode()
```

---

## Licencia

Uso no comercial. Ver encabezado del c√≥digo fuente original para t√©rminos completos.

---

*SYNTROPIA RADEON CORE V1.0 ‚Äî Arquitectura modular h√≠brida CPU/GPU para IA*
